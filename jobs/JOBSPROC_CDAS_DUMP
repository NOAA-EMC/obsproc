#!/bin/bash
set -xa
date -u

###################################################################
# Set DEBUG LEVEL - modifies info in execution trace prompt string
###################################################################
export DEBUG_LEVEL=${DEBUG_LEVEL=1}
case $DEBUG_LEVEL in
  1) export PS4='+ ${SECONDS}s + ' ;;       # add seconds (this is typical case)
  0) export PS4='+ ';;                      # don't include seconds (useful if
                                            #  want to diff output from 2 runs)
  2) export PS4='+ ${SECONDS}s:L$LINENO + ';;         # add script line #
  3) export PS4='+ ${SECONDS}s:${0##*/}:L$LINENO + ';;# add script name & line #
  4) export PS4='+ ${0##*/}:L$LINENO + ';;  # script name & line (no seconds)
  *) echo "Unrecognized DEBUG_LEVEL.  Stay with current PS4 setting";;
esac

########################################
# Check that required variables are set
########################################
set +x
echo
echo cyc is ${cyc:?"###FATAL ERROR \"cyc\" is not set"}
echo envir is ${envir:?"###FATAL ERROR \"envir\" is not set"}
echo job is ${job:?"###FATAL ERROR \"job\" is not set"}
echo DATAROOT is ${DATAROOT:?"###FATAL ERROR \"DATAROOT\" is not set"}
echo
set -x

################################
# Print out version information
################################
set +x
echo
echo "####################################################################"
echo
echo "OBSPROC version is ${obsproc_ver:-not set}"
echo "BUFR_DUMP version used by this job, for dump and dumplist, is" \
     "${bufr_dump_ver:-not set}"
echo "grib_util module version used by this job is ${grib_util_ver:-not set}"
if [[ $(echo $LOADEDMODULES | egrep -c "(^|:)bufr_dump/") -eq 0 ]];
     then echo "bufr_dump is required but not loaded! Exiting...";
     exit;
fi
echo
echo "####################################################################"
echo
set -x

#####################################################################
# List modules loaded for this job
#####################################################################
set +x
echo
echo "####################################################################"
echo
      module list
echo
echo "####################################################################"
echo
set -x

##################################
# Specify NET and RUN
##################################
export obsNET=${obsNET:-obsproc}
export NET=${NET:-cdas}
export RUN=${RUN:-cdas}
set +x
echo
echo obsNET is ${obsNET:?"###FATAL ERROR \"obsNET\" is not set"}
echo NET is ${NET:?"###FATAL ERROR \"NET\" is not set"}
echo RUN is ${RUN:?"###FATAL ERROR \"RUN\" is not set"}
echo
set -x

##############################
# Specify cycle and time-mark
##############################
export cycle=t${cyc}z
export tmmark=tm00

###############################
# Create new working directory
###############################
jobid=${jobid:-${job}.$(hostname -s).$$}
export DATA=${DATA:-$DATAROOT/${jobid}}
rm -rf $DATA
mkdir -p $DATA
cd $DATA
export pgmout=OUTPUT.$$
if [[ "$RUN_ENVIR" != nco ]]; then
  TMPDIR=$DATAROOT  # In the event TMPDIR is reset to a temporary LSF
                    #  directory when batch jobs are submitted, set it to
                    #  $DATAROOT so ensure it remains under the user's control
                    #  (normally needed only if child script dumpjb executed)
fi

######################################
# Set job log file for postmsg output
######################################
jlogfile=${jlogfile:-${DATA}/jlogfile}

#################################################
# SENDCOM      - Copy files to $COMOUT directory
# SENDECF      - Flag Events on ECFLOW
# SENDDBN      - Alert output file to TOC
#################################################
export SENDCOM=${SENDCOM:-YES}
export SENDECF=${SENDECF:-YES}
export SENDDBN=${SENDDBN:-YES}

##########################
# Specify Execution Areas
##########################

# -------------------------------
# Paths for obsproc items
# -------------------------------
export HOMEobsproc=${HOMEobsproc:\
-${PACKAGEROOT:?}/obsproc/${obsproc_ver:?\
"###FATAL ERROR \"obsproc_ver\" is not set"}}

export SCRIPTSobsproc=${SCRIPTSobsproc:\
-$HOMEobsproc/scripts}

# NOTE: path to dump executables defaults to $HOMEbufr_dump/exec in dumpjb

# directory path to data dump script executed in model script
# -----------------------------------------------------------
export ushscript_dump=${ushscript_dump:-$USHbufr_dump}

# ------------------------------------------
# Paths for combined obsproc and dump items
# ------------------------------------------

# directory paths to SSMI dump re-processing executed in bufr_dump_obs
# --------------------------------------------------------------------
export EXECPREP=${EXECPREP:-$HOMEbufr_dump/exec}
export PARMPREP=${PARMPREP:-$HOMEobsproc/parm}
export FIXPREP=${FIXPREP:-$HOMEbufr_dump/fix}

# directory paths to ERS, QuikSCAT & ASCAT dump re-processing executed in
#  bufr_dump_obs
# -----------------------------------------------------------------------
export EXECWAVE=${EXECWAVE:-$HOMEbufr_dump/exec}
export PARMWAVE=${PARMWAVE:-$HOMEobsproc/parm}
export FIXWAVE=${FIXWAVE:-$HOMEbufr_dump/fix}

# directory paths to SSMI & WindSAT dump re-processing executed in bufr_dump_obs
# ------------------------------------------------------------------------------
export EXECbufr=${EXECbufr:-$HOMEbufr_dump/exec}
export PARMbufr=${PARMbufr:-$HOMEobsproc/parm}
export FIXbufr=${FIXbufr:-$HOMEbufr_dump/fix}

# ---------------------------
# Paths for non-obsproc items
# ---------------------------

# TANK is root directory path to observational database used in dumpjb
#  and engice, sst & snowdepth grib files used in model script
# --------------------------------------------------------------------
export DCOMROOT=${DCOMROOT:-/lfs/h1/ops/prod/dcom}
export TANK=${TANK:-${DCOMROOT}}

# directory paths to engice, sst & snowdepth grib files used in model script
# --------------------------------------------------------------------------
export COM_ENGICE=${COM_ENGICE:-$(compath.py ${envir}/seaice_analysis/${seaice_analysis_ver})/seaice_analysis}
export COM_SSTOI=${COM_SSTOI:-$(compath.py $envir/nsst/${nsst_ver})/nsst} 
#export TANK_GRIBFLDS=${TANK_GRIBFLDS:-${DCOMROOT}/prod} # disabled in obsproc_cdas.v2.5.0

#########################################################################
# Add some prod utilities to working directory
#########################################################################
echo "step ############# break ##############################" > ./break
cp $UTILROOT/ush/err_chk   .; chmod +x err_chk
cp $UTILROOT/ush/err_exit  .; chmod +x err_exit
cp $UTILROOT/ush/prep_step .; chmod +x prep_step
cp $UTILROOT/ush/postmsg   .; chmod +x postmsg
cp $UTILROOT/ush/setpdy.sh .; chmod +x setpdy.sh

##########################################
# Run setpdy and initialize PDY variables
##########################################
set +x; echo -e "\n---> path to setpdy.sh below is: `which setpdy.sh`"; set -x
if [ -z "$PDY" ]; then
  if test "$cyc" = "06"
  then
    # With a very late cutoff, it is possible for the 06Z cycle
    # to move into the next day if production is running late -
    # to ensure that the YYYYMMDD are correct, use the /com/date/t12z
    # file for our PDY
    export cycle=t12z
    setpdy.sh
    . $DATA/PDY
    export cycle=t06z
    setpdy.sh
    . $DATA/PDY
  elif test "$cyc" = "18"
  then
    # With a very late cutoff, it is possible for the 18Z cycle
    # to move into the next day if production is running late -
    # to ensure that the YYYYMMDD are correct, use the /com/date/t00z
    # file to make PDY then backdate this PDY by 24-hours to get our PDY
    export cycle=t00z
    setpdy.sh
    . $DATA/PDY
    PDY=$PDYm1
    setpdy.sh
    . $DATA/PDY
    export cycle=t18z
    setpdy.sh
    . $DATA/PDY
  else
    # At 00 and 12Z, there should never be a problem
    setpdy.sh
    . $DATA/PDY
  fi
else
  # If PDY was previously specified (checkout only) fall through to here
  setpdy.sh
  . $DATA/PDY
fi

#########################
# Define COM directories
#########################
export COMIN_ROOT=${COMIN_ROOT:-${COMROOT:-""}}

if [[ "$RUN_ENVIR" == nco ]]; then
  export COMIN=${COMIN:-$(compath.py ${envir}/${obsNET}/${obsproc_ver}/${RUN}.${PDY})}
  export COMOUT=${COMOUT:-$(compath.py -o ${obsNET}/${obsproc_ver}/${RUN}.${PDY})}
  mkdir -m 775 -p $COMOUT
else
  export COMIN=${COMIN:-${COMIN_ROOT:?}/${obsNET}/${obsproc_ver}/${RUN}.${PDY}}

# COMOUT_ROOT for developers defaults to unique $DATA/com directory as root to
#  prevent job from writing into a non-unique directory that might already have
#  output in it from a previous checkout run for the same cycle
# -----------------------------------------------------------------------------
  export COMOUT_ROOT=${COMOUT_ROOT:-${DATA}/com}
  export COMOUT=${COMOUT:-${COMOUT_ROOT:?}/${obsNET}/${obsproc_ver}/${RUN}.${PDY}}
  mkdir -m 755 -p $COMOUT
fi

############################################
# SETUP CDAS DATA DUMP PROCESSING VARIABLES
############################################

#########################################################
# Specify variables specific to this execution of script
#########################################################
export PROCESS_GRIBFLDS=${PROCESS_GRIBFLDS:-YES}
export PROCESS_DUMP=${PROCESS_DUMP:-YES}
export COPY_TO_ARKV=${COPY_TO_ARKV:-YES}
export prepssmi=NO # "spssmi" reprocessed dump no longer generated
                   # since SSM/I instrument on F-13 has failed (11/2009)
export KEEP_NEARDUP_ACFT=${KEEP_NEARDUP_ACFT:-NO} # toss near-dupl. acft rpts

# During the period where both Goodberlet and NN3 SSM/I products are
#  being dumped, switch PREPSSMI_PROD_TYPE will direct the PREPSSMI
#  program to process from SSM/I data dumps that are either all GOODBERLET,
#  all NEURAL_NET3 or some COMBINATION of these two
#   -- rendered meaningless after 11/2009 since prepssmi now set to "no" (above)

export PREPSSMI_PROD_TYPE=COMBINATION

#  parallel processing options.  (note: cannot use launcher=cfp with MPMD=on)
export launcher=${launcher:-cfp}  # option to use cfp when processing dump groups
export MPMD=${MPMD:-off}  # option to use cfp in dumpjb
export BACK=${BACK:-off}  # option to use background threads in dumpjb

if [ $COPY_TO_ARKV == YES ]; then
  if [[ "$RUN_ENVIR" == nco ]]; then
    export COMARC=$(compath.py ${envir}/${obsNET}/${obsproc_ver}/${RUN}.`echo $PDY | cut -c1-6`)
    mkdir -m 775 -p $COMARC
  else
    export COMARC=${COMARC:-${COMOUT_ROOT:?}/${obsNET}/${obsproc_ver}/${RUN}.`echo $PDY | cut -c1-6`}
    mkdir -m 755 -p $COMARC
  fi
fi

env

#####################
# Execute the script
#####################
$SCRIPTSobsproc/excdas_dump.sh
eval err_${RUN}_dump=$?
eval [[ \$err_${RUN}_dump -ne 0 ]] && $DATA/err_exit

echo "$SITE `hostname`  --  `date -u`" > $COMOUT/where_${cycle}_${RUN}_dump_ran

> $COMOUT/obsproc_version_for_${cycle}_${RUN}_dump_run
[ -n "$obsproc_ver" ]  &&  \
 echo "OBSPROC version is $obsproc_ver" >> \
 $COMOUT/obsproc_version_for_${cycle}_${RUN}_dump_run
[ -n "$bufr_dump_ver" ]  &&  \
 echo "BUFR_DUMP version used by this job is $bufr_dump_ver" >> \
 $COMOUT/obsproc_version_for_${cycle}_${RUN}_dump_run
echo "Version of module \"grib_util\" used by this job is $grib_util_ver" \
 >> $COMOUT/obsproc_version_for_${cycle}_${RUN}_dump_run

if [ "$KEEPDATA" != YES ]; then
   cd $DATAROOT
   rm -rf $DATA
fi
date -u

exit
